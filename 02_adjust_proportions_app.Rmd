---
title: "Adjustments"
output:
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
runtime: shiny
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(here)
library(vroom)
library(plotly)
library(shiny)
library(kableExtra)
library(conflicted)
library(viridis)
conflicts_prefer(vroom::cols)
conflicts_prefer(vroom::col_double)
conflicts_prefer(vroom::col_character)
conflicts_prefer(dplyr::filter)
conflicts_prefer(plotly::layout)
cagr_horizon <- 10
options(scipen = 999)
#functions--------------------------------------
source(here("..","shared_functions", "pond_utilities.R"))
margin_plot <- function(tbbl, tbbl2, margin, title){
  plt <- ggplot()+
    geom_point(data=tbbl2, 
               mapping=aes(year, 
                           employment,
                            text=paste0(
                            "Census",
                            "\n Employment: ",
                            scales::comma(employment, accuracy = 1),
                            "\n Year: ",
                            year)),
               alpha=.5)+
    geom_line(data=tbbl, 
              mapping=aes(year, 
                          employment, 
                          colour=series, 
                          lty=series,
                          group=series,
                          text=paste0(
                            description,
                            "\n Employment: ",
                            scales::comma(employment, accuracy = 1),
                            "\n Year: ",
                            year,
                            "\n Modified 10 year CAGR: ",
                            mod_cagr,
                            "\n Pre modification 10 year CAGR: ",
                            pre_cagr,
                            "\n 10 year historic CAGR: ",
                            historic_cagr
                            )))+
    facet_wrap(~ get(margin), scales = "free_y")+
    labs(title=title,
      x=NULL,
         y=NULL)+
    theme_minimal()+
    theme(text=element_text(size=13),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks.y=element_blank())
  ggplotly(plt, tooltip = "text")
}
get_total <- function(tbbl){
   sum(tbbl$employment)
 } 
get_cagr <- function(tbbl, horizon){
  max_year <- max(tbbl$year)
  start <- tbbl$employment[tbbl$year==max_year-horizon]
  end <-  tbbl$employment[tbbl$year==max_year]
  if_else(start==0, NA_real_, (end/start)^(1/horizon)) 
}
occ_plot <- function(pg){
  plt <- bind_rows(occupation_historic, post_mod_occupation(), pre_mod_occupation())|> 
    filter(page==pg)|>
    left_join(noc_descriptions)|>
    left_join(occupation_pre_cagrs()|>mutate(pre_cagr=scales::percent(pre_cagr, accuracy=.1)))|>
    left_join(occupation_mod_cagrs()|>mutate(mod_cagr=scales::percent(mod_cagr, accuracy=.1)))|>
    left_join(occupation_historic_cagrs|>mutate(historic_cagr=scales::percent(historic_cagr, accuracy=.1)))|>
    ggplot()+
    geom_point(data=occupation_census|>filter(page==pg),
               mapping=aes(year, 
                   employment, 
                   text=paste0("Census",
                               "\n Employment: ",
                               scales::comma(employment, accuracy = 1),
                               "\n Year: ",
                               year)),
               alpha=.5)+
      geom_line(aes(year, 
                    employment, 
                    colour=series, 
                    lty=series,
                    group=series,
                    text=paste0(class_title,
                                "\n Employment: ",
                                scales::comma(employment, accuracy = 1),
                                "\n Year: ",
                                year,
                                "\n Modified 10 year CAGR: ",
                                mod_cagr,
                                "\n Pre modification 10 year CAGR: ",
                                pre_cagr,
                                "\n 10 year historic CAGR: ",
                                historic_cagr)
                    )
                )+
      facet_wrap(~noc_5, scales = "free_y")+
      labs(title="Occupation time plots (aggregated across region and industry)",
        x=NULL,
           y=NULL)+
      theme_minimal()+
      theme(text=element_text(size=13),
            axis.text.x=element_blank(),
            axis.ticks.x=element_blank(),
            axis.text.y=element_blank(),
            axis.ticks.y=element_blank())
  ggplotly(plt, tooltip = "text")
}

# read in the data----------------------------
industry_mapping <- readxl::read_excel(resolve_current("industry_mapping_with_stokes_agg.xlsx"))|>
  select(aggregate_industry, lmo_ind_code)|>
  distinct()|>
  filter(!str_detect(lmo_ind_code, "Total"))
for_shrinkage_plot <- read_rds(here("out","for_shrinkage_plot.rds"))
mod_shares <-  read_rds(here("out","modified","shares.rds")) #forecast shares, overwritten on each save
bc_fcast <- read_rds(here("out","modified","bc_forecast.rds")) #the BC finance forecast plus 6 years.
regions <- unique(mod_shares$bc_region)
industries <- sort(unique(mod_shares$lmo_ind_code))
occupations <- sort(unique(mod_shares$noc_5))

noc_descriptions <- vroom(resolve_current("noc_descriptions.csv"), 
                          col_types = cols(noc_5 = col_character(), lmo_noc=col_character(), class_title = col_character()),
                          delim=",")|>
  select(noc_5=lmo_noc, class_title)|>
  distinct()|>
  mutate(noc_5=str_pad(noc_5, width=5, pad="0"))

region_historic <- read_rds(here("out","historic_bc_region.rds"))
industry_historic <- read_rds(here("out", "historic_lmo_ind_code.rds"))
occupation_historic <- read_rds(here("out","historic_noc_5.rds"))|>
  left_join(noc_descriptions)|>
  arrange(noc_5)|>
  mutate(page=ntile(n=8))|>
  group_by(page)|>
  mutate(page_description=paste0(min(noc_5),"-",max(noc_5)))|>
  filter(noc_5 %in% occupations)

noc_pages <- occupation_historic|> #by NOC aggregates need to be split across multiple pages.
  select(noc_5, class_title, page)|>
  distinct()

region_census <- read_rds(here("out","census_region.rds"))
industry_census <- read_rds(here("out","census_industry.rds"))

aggregate_census <- industry_census|>
    left_join(industry_mapping, by=join_by("lmo_ind_code"))|>
    group_by(year, aggregate_industry, series)|>
    summarize(employment=sum(employment))

occupation_census <- read_rds(here("out","census_occupation.rds"))|>
  left_join(noc_descriptions)|>
  arrange(noc_5)|>
  filter(noc_5 %in% occupations)|>
  inner_join(noc_pages)

#non-reactive growth rates
regional_historic_cagrs <- region_historic|>
  group_by(bc_region)|>
  nest()|>
  mutate(historic_cagr=map_dbl(data, get_cagr, cagr_horizon),
         historic_cagr=historic_cagr-1)|>
  select(-data)

industry_historic_cagrs <- industry_historic|>
  group_by(lmo_ind_code)|>
  nest()|>
  mutate(historic_cagr=map_dbl(data, get_cagr, cagr_horizon),
         historic_cagr=historic_cagr-1)|>
  select(-data)

occupation_historic_cagrs <- occupation_historic|>
  group_by(noc_5)|>
  nest()|>
  mutate(historic_cagr=map_dbl(data, get_cagr, cagr_horizon),
         historic_cagr=historic_cagr-1)|>
  select(-data)
```

# Inputs {.sidebar}

```{r}

sliderInput("bc_shift", "Shift BC employment forecast",
  min = .99, max = 1.01,
  value = 1, step = .001
)

# shiny inputs defined here
selectInput(
  "margin",
  "What margin do you want to manipulate?",
  c("bc_region", "noc_5", "lmo_ind_code"),
  "lmo_ind_code"
)
```

```{r}

dropdown <- reactive({
  if(input$margin=="bc_region"){
    regions
  }else if(input$margin=="noc_5"){
    occupations
  }else if(input$margin=="lmo_ind_code"){
    industries
  }else{
    stop("Error: select margin")
  }
})

renderUI({#need the renderUI because dropdown list is a reactive object
  selectInput('item', 
              'What item do you want to manipulate?', 
              dropdown()
              )
})

sliderInput("shift", "Shift up or down",
  min = .5, max = 1.5,
  value = 1, step = .01
)
sliderInput("slope", "Change slope",
  min = .95, max = 1.05,
  value = 1, step = .001
)
actionButton("save", "Save modified shares to disk")
```

```{r}
#reactive elements

bc_reactive <- reactive({
  last_year_of_budget <- bc_fcast|>
    filter(series=="budget forecast")|>
    summarize(max(year))|>
    pull()
  modified <- bc_fcast|>
    mutate(employment=if_else(series=="our forecast", 
                              employment*input$bc_shift, 
                              employment))
  lfs_and_finance <- modified|>
    filter(series %in% c("LFS", "budget forecast"))
  our_forecast <- modified|>
    filter(series=="our forecast")|>
    mutate(cagr=(employment[year==max(year)]/employment[year==min(year)])^(1/(max(year)-min(year)))-1)
  bind_rows(lfs_and_finance, our_forecast)
})

shares <- reactive({#the shares after the current modification (slope and shift)
  mod_shares|>
      ungroup()|>
      mutate(multiplier=if_else(get(input$margin) == input$item, 
                                input$shift*input$slope^(year-min(year)), 
                                1))|>
    group_by(year)|>
    mutate(post_mod_share=pre_mod_share*multiplier,
           post_mod_share=post_mod_share/sum(post_mod_share)) #proportions must sum to 1
})
# the cell forecasts pre and post modification
pre_mod_forecast <- reactive({
 inner_join(shares(), bc_reactive())|>
    mutate(employment=pre_mod_share*employment,
           series="Pre modification")
})
post_mod_forecast <- reactive({
  inner_join(shares(), bc_reactive())|>
    mutate(employment=post_mod_share*employment,
           series="Post modification")
})
# regional aggregates of the pre and post modification forecasts
pre_mod_region <- reactive({
  pre_mod_forecast()|>
    group_by(year, bc_region, series)|>
    summarize(employment=sum(employment))
})
post_mod_region <- reactive({
  post_mod_forecast()|>
    group_by(year, bc_region, series)|>
    summarize(employment=sum(employment))
})
# industry aggregates of the pre and post modification forecasts
pre_mod_industry <- reactive({
  pre_mod_forecast()|>
    group_by(year, lmo_ind_code, lmo_detailed_industry, series)|>
    summarize(employment=sum(employment))
})
post_mod_industry <- reactive({
  post_mod_forecast()|>
    group_by(year, lmo_ind_code, lmo_detailed_industry, series)|>
    summarize(employment=sum(employment))
})
# occupation aggregates of the pre and post modification forecasts
pre_mod_occupation <- reactive({
  pre_mod_forecast()|>
    group_by(year, noc_5, series)|>
    summarize(employment=sum(employment))|>
    full_join(noc_pages)
})
post_mod_occupation <- reactive({
  post_mod_forecast()|>
    group_by(year, noc_5, series)|>
    summarize(employment=sum(employment))|>
    full_join(noc_pages)
})
# the CAGRs of the modified aggregate forecasts
regional_mod_cagrs <- reactive({
  post_mod_region()|>
    group_by(bc_region)|>
    nest()|>
    mutate(mod_cagr=map_dbl(data, get_cagr, 10),
           mod_cagr=mod_cagr-1)|>
    select(bc_region, mod_cagr)
})
industry_mod_cagrs <- reactive({
  post_mod_industry()|>
    group_by(lmo_ind_code)|>
    nest()|>
    mutate(mod_cagr=map_dbl(data, get_cagr, 10), 
           mod_cagr=mod_cagr-1)|>
    select(lmo_ind_code, mod_cagr)
})
occupation_mod_cagrs <- reactive({
  post_mod_occupation()|>
    group_by(noc_5)|>
    nest()|>
    mutate(mod_cagr=map_dbl(data, get_cagr, 10), 
           mod_cagr=mod_cagr-1)|>
    select(noc_5, mod_cagr)      
})
# the CAGRs of the pre modification aggregate forecasts
regional_pre_cagrs <- reactive({
  pre_mod_region()|>
    group_by(bc_region)|>
    nest()|>
    mutate(pre_cagr=map_dbl(data, get_cagr, 10),
           pre_cagr=pre_cagr-1)|>
    select(bc_region, pre_cagr)
})
industry_pre_cagrs <- reactive({
  pre_mod_industry()|>
    group_by(lmo_ind_code)|>
    nest()|>
    mutate(pre_cagr=map_dbl(data, get_cagr, 10), 
           pre_cagr=pre_cagr-1)|>
    select(lmo_ind_code, pre_cagr)
})
occupation_pre_cagrs <- reactive({
  pre_mod_occupation()|>
    group_by(noc_5)|>
    nest()|>
    mutate(pre_cagr=map_dbl(data, get_cagr, 10), 
           pre_cagr=pre_cagr-1)|>
    select(noc_5, pre_cagr)      
})
#writing the modified proportions to disk
observeEvent(input$save, {
  shares()|> #give the modified share tbbl same structure as pre_mod_share tbbl, and overwrite.
    select(-pre_mod_share, -multiplier)|>
    rename(pre_mod_share=post_mod_share)|>
    write_rds(here("out","modified", "shares.rds"))
  
  tibble("margin"=input$margin, #append this change to the change log.
         "item"=input$item, 
         "shift"=input$shift, 
         "slope"=input$slope)|>
    write.table(here("out","change_log", "changes.csv"),
    append = TRUE,
    quote = TRUE,
    sep = ",",
    row.names = FALSE,
    col.names = !file.exists(here("out","change_log", "changes.csv"))
  )
  #overwrite the top level forecast
  bc_reactive()|>
    write_rds(here("out","modified", "bc_forecast.rds"))
})
```

# BC

### 

```{r}
plotly::renderPlotly({
  plt <- ggplot(bc_reactive(), aes(year, 
                            employment, 
                            colour=series,
                            group=series,
                            text=paste0(
                              "Series: ",
                              series,
                              "\n Employment: ",
                              scales::comma(employment, accuracy = 1),
                              "\n Year: ",
                              year,
                              "\n CAGR: ",
                              scales::percent(cagr, accuracy = .01)
                            )))+
  geom_line()+
  theme_minimal()+
  scale_y_continuous(labels = scales::comma)+
  labs(title="BC time plot (aggregated across region, industry, occupation)",
    x=NULL, y=NULL, colour=NULL)
ggplotly(plt, tooltip = "text")
})
```

# Region

### 

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
  bind_rows(region_historic, post_mod_region(), pre_mod_region())|>
    mutate(description=bc_region)|>
    full_join(regional_mod_cagrs()|>mutate(mod_cagr=scales::percent(mod_cagr, accuracy=.1)))|>
    full_join(regional_pre_cagrs()|>mutate(pre_cagr=scales::percent(pre_cagr, accuracy=.1)))|>
    full_join(regional_historic_cagrs|>mutate(historic_cagr=scales::percent(historic_cagr, accuracy=.1)))|>
    margin_plot(region_census, "bc_region", "Regional time plots (aggregated across industry and occupation)")
})
```

# Industry

## Row {.tabset}

### LMO 63 Industries

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
  bind_rows(industry_historic, post_mod_industry(), pre_mod_industry())|>
    rename(description=lmo_detailed_industry)|>
    full_join(industry_mod_cagrs()|>mutate(mod_cagr=scales::percent(mod_cagr, accuracy=.1)))|>
    full_join(industry_pre_cagrs()|>mutate(pre_cagr=scales::percent(pre_cagr, accuracy=.1)))|>
    full_join(industry_historic_cagrs|>mutate(historic_cagr=scales::percent(historic_cagr, accuracy=.1)))|>
    margin_plot(industry_census, "lmo_ind_code", "LMO 63 Industry time plots (aggregated across region and occupation)")
})
```

### Aggregate Industries

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
 
  bind_rows(industry_historic, post_mod_industry(), pre_mod_industry())|>
    left_join(industry_mapping, by=join_by("lmo_ind_code"))|>
    group_by(year, aggregate_industry, series)|>
    summarize(employment=sum(employment))|>
    ggplot()+
    geom_point(data=aggregate_census, mapping = aes(year, employment), alpha=.5)+
    geom_line(mapping= aes(year, employment, colour=series))+
    facet_wrap(~aggregate_industry, scales="free_y")+
    theme_minimal()+
    labs(x=NULL,
         y=NULL)+
    theme_minimal()+
    theme(text=element_text(size=8),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks.y=element_blank())
})
```


# Occupation

## Row {.tabset}

### `r unique(occupation_historic$page_description[occupation_historic$page==1])`

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
occ_plot(1)
})
```

### `r unique(occupation_historic$page_description[occupation_historic$page==2])`

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
occ_plot(2)
})
```

### `r unique(occupation_historic$page_description[occupation_historic$page==3])`

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
occ_plot(3)
})
```

### `r unique(occupation_historic$page_description[occupation_historic$page==4])`

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
occ_plot(4)
})
```

### `r unique(occupation_historic$page_description[occupation_historic$page==5])`

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
occ_plot(5)
})
```

### `r unique(occupation_historic$page_description[occupation_historic$page==6])`

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
occ_plot(6)
})
```

### `r unique(occupation_historic$page_description[occupation_historic$page==7])`

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
occ_plot(7)
})
```

### `r unique(occupation_historic$page_description[occupation_historic$page==8])`

```{r, fig.retina=2}
renderPlotly({
  req(input$margin)
  req(input$item)
occ_plot(8)
})
```

# Region

```{r}
renderPlotly({
  req(input$margin)
  req(input$item)
  plt <- post_mod_region()|>
    group_by(bc_region)|>
    summarize(employment=sum(employment))|>
    mutate(share=employment/sum(employment))|>
    full_join(regional_mod_cagrs())|>
    ggplot(aes(share, 
            mod_cagr, 
            text=paste0("Region: ",
                        bc_region,
                        "\n Growth rate: ",
                        scales::percent(mod_cagr, accuracy=.1),
                        "\n Share: ",
                        scales::percent(share, accuracy=.1)  
                        )))+
    geom_point(alpha=.5)+
    scale_x_continuous(trans="log10", labels = scales::percent)+
    scale_y_continuous(labels=scales::percent)+
    theme_minimal()+ 
    theme(text=element_text(size=20))+
    labs(x="Share",
         y="Forecast 10 year CAGR")
  ggplotly(plt, tooltip = "text")
})
```

# Industry 

```{r}
renderPlotly({
  req(input$margin)
  req(input$item)
  plt <- post_mod_industry()|>
    group_by(lmo_ind_code, lmo_detailed_industry)|>
    summarize(employment=sum(employment))|>
    ungroup()|>
    mutate(share=employment/sum(employment))|>
    full_join(industry_mod_cagrs())|>
    ggplot(aes(share,
               mod_cagr,
               text=paste0(paste(lmo_ind_code, lmo_detailed_industry, sep=": "),
                        "\n Growth rate: ",
                        scales::percent(mod_cagr, accuracy=.1),
                        "\n Share: ",
                        scales::percent(share, accuracy=.01)
                        )))+
    geom_point(alpha=.5)+
    scale_x_continuous(trans="log10", labels = scales::percent)+
    scale_y_continuous(labels=scales::percent)+
    theme_minimal()+
    theme(text=element_text(size=20))+
    labs(x="Share",
         y="Forecast 10 year CAGR")
  ggplotly(plt, tooltip = "text")
})
```

# Occupation 

```{r}
renderPlotly({
  req(input$margin)
  req(input$item)
  plt <- post_mod_occupation()|>
    group_by(noc_5)|>
    summarize(employment=sum(employment, na.rm=TRUE))|>
    mutate(share=employment/sum(employment, na.rm=TRUE))|>
    full_join(noc_descriptions)|>
    full_join(occupation_mod_cagrs())|>
 ggplot(aes(share, 
            mod_cagr,
            text=paste0(noc_5,
                        ": ",
                        class_title,
                        "\n Growth rate: ",
                        scales::percent(mod_cagr, accuracy=.1),
                        "\n Share: ",
                        scales::percent(share, accuracy=.0001)  
                        )))+
    geom_point(alpha=.5)+
    scale_x_continuous(trans="log10", labels=scales::percent)+
    scale_y_continuous(labels=scales::percent)+
    theme_minimal()+
    theme(text=element_text(size=20))+
    labs(x="Share",
         y="Forecast 10 year CAGR")
  ggplotly(plt, tooltip = "text")
})
```

# Why?

#### Potential Benefits

- Forecast would be available on Budget day.
- It could be used in early stakeholder consultations: e.g. "This is our first cut forecast for your industry (and top occupations within), what do you think?"
- It could serve as a point of reference for the numerous Stokes model cuts.
- Unlike the Stokes model, where we are increasingly constrained (e.g. we can't change this without messing up that), any dimension can be changed at any point, and the model rebalances to respect the top level constraint.  

#### Limitations

-  I have not incorporated the "driver" forecasts or information from major projects: the model is purely backward looking.

-  That being said, this app allows the user to modify/match the overall level and growth rate of slices (region, industry, occupation) of the labour market. 

# Baseline

### Baseline Proportions

-   For the BC LMO we are constrained by the Finance forecast.

-   Given this constraint, in effect we are forecasting proportions of BC employment.

-   Using census 2021 and monthly LFS data from the years 2017:2025, we calculate baseline proportions of BC employment based on every combination of region, industry and occupation.

-   Specifically, the baseline proportions are a weighted average of Census and LFS proportions, where the weight on Census is 0.79 and the weight on LFS is 0.21.

-   These weights reflect the effective sample size (number of workers covered) of the two sources:

```{r, echo=FALSE}
kable(
  tibble(
    Source = c("LFS (9 years)", "Census (2021)"),
    `Effective N (distinct workers)` = c("~1.29 million", "~4.8 million")
  ),
  caption = "Effective sample size of LFS and Census data"
)|>
  kable_styling(full_width = FALSE, position = "left")
```

-  If we applied these weighted proportions to BC's aggregate employment forecast, **every** combination of region, industry and occupation would grow at the same rate as BC as a whole.

#### Calculation of Effective N

##### Census

- In 2021 there were 14,978,940 occupied private households in Canada, of which 25% received the long form census: 3,744,735 households.
- The total number of employed in Canada was 19,166,110.  If we divide the total employed by the number of households we get 1.28 workers per household.
- Thus the 2021 Census collected labour market information on approximately 4.8 million workers.

##### Labour Force Survey

-   Survey is sent to 56,000 households each month, 1/6th of which are new to the sample (LFS uses rotating panel where household followed for 6 months).
-   Distinct households sampled over 108 months ≈ (56,000/6)*108 = 1,008,000.
-   Given the 1.28 workers per household calculated above, LFS covered approximately 1.29 million distinct workers over 9 years.

# Change 

Column 
-------------------------------------

### Buckle up... its time to get Baysian

-  Next we describe how we model the evolution of employment shares over time.

-  We first estimate the growth rate of BC as a whole by fitting the model
\[
\log(\text{Employment} + 1) = \alpha + \beta\,\text{year} + \varepsilon .
\]

-  Adding 1 ensures the logarithm is defined if employment=0.

-  The slope coefficient $\hat{\beta}_{BC}$ serves as our prior belief about growth—what we would expect in the absence of any slice-specific information.

-  We then estimate separate trends for the 7 regions, 63 industries, and 512 occupations. 

-  For each slice $s$, we obtain a slope estimate $\hat{\beta}_{s}$ and its standard error $SE(\hat{\beta}_{s})$.

-  The question is: how convincing is each slice’s estimated trend? In other words, how much should we update our prior belief?

-  Two quantities govern the update: the sampling variance of the slice trend

\[
(SE(\hat{\beta}_{s}))^{2},
\]

and the cross-slice variance in trends *within* a group (e.g. region).

\[
\tau^{2} = \mathrm{Var}(\hat{\beta}_{s} - \hat{\beta}_{BC}),
\]


-  If a slice’s slope is estimated precisely and there is substantial heterogeneity across slices, we rely mostly on the slice estimate (yellow areas in the heatmap). 

-  If a slice’s slope is imprecise and there is little heterogeneity across slices, we shrink strongly toward the BC-wide trend (purple areas).

-  Formally, the posterior (shrunk) slope for slice $s$ is

\[
\tilde{\beta}_{s} = w_s \hat{\beta}_{s} + (1 - w_s)\hat{\beta}_{BC},
\]
where the weight on the slice estimate is
\[
w_s = \frac{\tau^{2}}{\tau^{2} + (SE(\hat{\beta}_{s}))^{2}} .
\]



Column {.tabset}
-------------------------------------

### Weight on $\hat{\beta_s}$

```{r}
var <- seq(0,1,.01)
tau2 <- var

tbbl <- crossing(var, tau2)|>
  mutate(weight=tau2/(var+tau2))

plot_ly(
  data = tbbl,
  x = ~var,
  y = ~tau2,
  z = ~weight,
  type = "heatmap",
  colors = viridis(100, option = "D"),
  zmin = min(tbbl$weight, na.rm = TRUE),
  zmax = max(tbbl$weight, na.rm = TRUE),
  showscale = TRUE,
  text = ~paste0(
    "SE(β)²: ", signif(var, 4), "<br>",
    "τ²: ", signif(tau2, 4), "<br>",
    "ω: ", signif(weight, 4)
  ),
  hoverinfo = "text"
) %>%
  layout(
    xaxis = list(title = "SE(β)²"),
    yaxis = list(title = "τ²")
  ) %>%
  colorbar(title = list(text = "ω"))
```

### $\hat{\beta}_s$ vs Shrunken slope (NOCs)

```{r}
bc_slope <- for_shrinkage_plot$bc_slope[1]

plt <- ggplot(for_shrinkage_plot, aes(slope, shrunk_slope, colour=size, label=noc_5))+
  geom_abline(slope=1, intercept = 0, colour="white", lwd=3)+
  geom_vline(xintercept = bc_slope, colour="white", lwd=3)+
  geom_hline(yintercept = bc_slope, colour="white", lwd=3)+
  geom_point()+
  geom_rug()+
  scale_colour_viridis_c(trans="log10", labels=scales::comma)+
  labs(x="Original Slope",
       y="Shrunken Slope",
       colour="Employment")+
  xlim(-.25,.2)+
  ylim(-.25,.2)


plotly::ggplotly(plt)%>%
  layout(
    autosize = FALSE,
    width = 600,
    height = 500,
    xaxis = list(scaleanchor = "y"),
    yaxis = list(scaleanchor = "x"),
    legend = list(orientation = "h",
                  x = 0.5, xanchor = "center",
                  y = -0.15)
  )
```

# Growth Factors

-  In order to convert the shrunken slope coefficients to growth factors we exponentiate: e.g. if $\hat{\beta}_s=-.016$ then "growth" factor is $e^{-.016}=0.984$
-  We then apply these marginal growth factors to the baseline proportions for the forecast horizon.
-   For example, suppose that a region/industry/occupation combination accounted for an estimated 1% of the BC labour market in 2021. Suppose that region's growth factor is 1.02, the industry's growth factor is 1.03, and the occupation's growth factor is .96
-   For the forecast year $t$ years after 2021, the un-adjusted proportion is $.01\times(1.02^{t}\times1.03^{t}\times.96^{t})^\frac13$.
-   Note that regarding the *change* in proportions over time, region, industry and occupation are assumed to be independent.
-   This is in contrast to the baseline *levels*, where the sparsity alone indicates strong dependency between region, industry and occupation.
-   Note that these un-adjusted proportions will not necessarily sum to 1: we adjust so they do so.




# Example

###

-  Suppose that we want to increase the proportion of employment in region 2.
-  Every cell on level 2 of the cube would increase by the same proportion, maintaining the relative noc-naics composition within that region.
-  Every cell not on level 2 would diminish to compensate, again maintaining the relative noc-naics composition within those regions.
-  The same holds true for manipulating either an industry or occupation (vertical slices): every cell in that slice of the cube would increase by the same proportion, and every cell not in the slice would diminish to compensate, again maintaining the relative composition of the remaining two dimensions.

###


<img src="Screenshot from 2025-06-09 08-46-31.png" width="100%" />



